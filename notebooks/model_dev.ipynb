{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb91042",
   "metadata": {},
   "source": [
    "## 1. ðŸšš Data Loading & Preparation\n",
    "\n",
    "Let's start by loading the pre-cleaned MovieLens ratings data and prepping it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad49b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the dataset:\n",
      "   user_id  movie_id  rating            timestamp                       title  \\\n",
      "0      196       242       3  1997-12-04 15:55:49                Kolya (1996)   \n",
      "1      186       302       3  1998-04-04 19:22:22    L.A. Confidential (1997)   \n",
      "2       22       377       1  1997-11-07 07:18:36         Heavyweights (1994)   \n",
      "3      244        51       2  1997-11-27 05:02:03  Legends of the Fall (1994)   \n",
      "4      166       346       1  1998-02-02 05:33:16         Jackie Brown (1997)   \n",
      "\n",
      "  release_date  video_release_date  \\\n",
      "0  24-Jan-1997                 NaN   \n",
      "1  01-Jan-1997                 NaN   \n",
      "2  01-Jan-1994                 NaN   \n",
      "3  01-Jan-1994                 NaN   \n",
      "4  01-Jan-1997                 NaN   \n",
      "\n",
      "                                            IMDb_URL  unknown  Action  ...  \\\n",
      "0    http://us.imdb.com/M/title-exact?Kolya%20(1996)        0       0  ...   \n",
      "1  http://us.imdb.com/M/title-exact?L%2EA%2E+Conf...        0       0  ...   \n",
      "2  http://us.imdb.com/M/title-exact?Heavyweights%...        0       0  ...   \n",
      "3  http://us.imdb.com/M/title-exact?Legends%20of%...        0       0  ...   \n",
      "4  http://us.imdb.com/M/title-exact?imdb-title-11...        0       0  ...   \n",
      "\n",
      "   Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  \\\n",
      "0        0          0       0        0        0        0       0         0   \n",
      "1        0          1       0        0        1        0       0         1   \n",
      "2        0          0       0        0        0        0       0         0   \n",
      "3        0          0       0        0        0        1       0         0   \n",
      "4        0          0       0        0        0        0       0         0   \n",
      "\n",
      "   War  Western  \n",
      "0    0        0  \n",
      "1    0        0  \n",
      "2    0        0  \n",
      "3    1        1  \n",
      "4    0        0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned ratings data\n",
    "df = pd.read_csv(\"../data/movielens/cleaned_ratings.csv\")\n",
    "print(\"Sample of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c100f",
   "metadata": {},
   "source": [
    "### Explanation: \n",
    "> The dataaset contains user ratings for movies, with each row representing a rating containing the `user_id, movie_id, rating, timestamp, title`. I will be focusing on user, movie_id, and rating for the baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c98a5",
   "metadata": {},
   "source": [
    "## 2. Data Formatting for TensorFlow\n",
    "Here we shuffle and split the data to ensure a fair evaluation and avoid overfitting. IDs are converted to strings so they can be embedded by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15873b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ensure user and movie IDs are strings for embeddings\n",
    "df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "df[\"movie_id\"] = df[\"movie_id\"].astype(str)\n",
    "\n",
    "# Shuffle and split data\n",
    "shuffled = df.sample(frac=1, random_state=42)\n",
    "n = int(len(shuffled) * 0.8)\n",
    "train = shuffled.iloc[:n]\n",
    "test = shuffled.iloc[n:]\n",
    "\n",
    "# Convert to tf.data.Dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": train[\"user_id\"].values,\n",
    "    \"movie_id\": train[\"movie_id\"].values,\n",
    "    \"rating\": train[\"rating\"].astype(float).values,\n",
    "})\n",
    "test_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": test[\"user_id\"].values,\n",
    "    \"movie_id\": test[\"movie_id\"].values,\n",
    "    \"rating\": test[\"rating\"].astype(float).values,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8a9e7",
   "metadata": {},
   "source": [
    "## 3. Building a Two-Tower Deep Learning Model\n",
    "We'll use a two-tower architecture, where one tower learns user representations and the other learns movie representations. Their similarity determines recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f117eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.16.1\n",
      "TFRS: v0.7.3\n",
      "Type of unique_movie_ids: <class 'numpy.ndarray'>\n",
      "Length of unique_movie_ids: 1651\n",
      "Sample of unique_movie_ids: ['381' '602' '431' '875' '182' '1074' '286' '496' '15' '184']\n",
      "candidates: <_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>\n",
      "tf.Tensor(\n",
      "[b'381' b'602' b'431' b'875' b'182' b'1074' b'286' b'496' b'15' b'184'\n",
      " b'864' b'568' b'1197' b'99' b'31' b'14' b'176' b'618' b'476' b'82' b'492'\n",
      " b'303' b'408' b'483' b'180' b'109' b'156' b'1281' b'2' b'979' b'214'\n",
      " b'1165' b'245' b'326' b'651' b'95' b'45' b'318' b'684' b'682' b'38'\n",
      " b'257' b'77' b'1091' b'647' b'230' b'636' b'276' b'386' b'519' b'1086'\n",
      " b'205' b'187' b'234' b'934' b'240' b'742' b'547' b'273' b'1448' b'195'\n",
      " b'204' b'569' b'235' b'810' b'1015' b'845' b'324' b'26' b'219' b'1016'\n",
      " b'28' b'628' b'1446' b'288' b'395' b'100' b'83' b'428' b'289' b'278'\n",
      " b'111' b'271' b'269' b'1142' b'175' b'473' b'125' b'121' b'190' b'610'\n",
      " b'11' b'50' b'844' b'298' b'919' b'762' b'97' b'1210' b'1059' b'9' b'172'\n",
      " b'68' b'106' b'700' b'737' b'1051' b'1115' b'740' b'1033' b'1109' b'414'\n",
      " b'1333' b'559' b'268' b'990' b'1590' b'741' b'284' b'262' b'654' b'1063'\n",
      " b'1' b'1054' b'309' b'290' b'69' b'931'], shape=(128,), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 12:43:23.916398: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"TFRS:\", tfrs.__version__)\n",
    "\n",
    "unique_user_ids = np.array(train[\"user_id\"].astype(str).unique())\n",
    "unique_movie_ids = np.array(train[\"movie_id\"].astype(str).unique())\n",
    "\n",
    "# Debug prints\n",
    "print(\"Type of unique_movie_ids:\", type(unique_movie_ids))\n",
    "print(\"Length of unique_movie_ids:\", len(unique_movie_ids))\n",
    "print(\"Sample of unique_movie_ids:\", unique_movie_ids[:10])\n",
    "assert isinstance(unique_movie_ids, (np.ndarray, list)), f\"Not array/list: {type(unique_movie_ids)}\"\n",
    "assert isinstance(unique_movie_ids[0], str), f\"Not string: {type(unique_movie_ids[0])}\"\n",
    "\n",
    "# debugging candidates\n",
    "candidates = tf.data.Dataset.from_tensor_slices(unique_movie_ids).batch(128)\n",
    "print(\"candidates:\", candidates)\n",
    "for batch in candidates.take(1):\n",
    "    print(batch)\n",
    "\n",
    "class MovieLensModel(tfrs.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dim = 32\n",
    "\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_movie_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_ids) + 1, embedding_dim)\n",
    "        ])\n",
    "\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=candidates\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_id\"])\n",
    "        return self.task(user_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903eee3a",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "Training recommendation model based on training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aefc9b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '('c', 'o', 'u', 'n', 't', 'e', 'r')' to a shape. Found invalid entry 'c' of type '<class 'str'>'. ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m cached_train = train_ds.shuffle(\u001b[32m100_000\u001b[39m).batch(\u001b[32m8192\u001b[39m).cache()\n\u001b[32m      3\u001b[39m cached_test = test_ds.batch(\u001b[32m4096\u001b[39m).cache()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mMovieLensModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m model.compile(optimizer=tf.keras.optimizers.Adagrad(\u001b[32m0.1\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mMovieLensModel.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mself\u001b[39m.user_model = tf.keras.Sequential([\n\u001b[32m     29\u001b[39m     tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=\u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     30\u001b[39m     tf.keras.layers.Embedding(\u001b[38;5;28mlen\u001b[39m(unique_user_ids) + \u001b[32m1\u001b[39m, embedding_dim)\n\u001b[32m     31\u001b[39m ])\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.movie_model = tf.keras.Sequential([\n\u001b[32m     33\u001b[39m     tf.keras.layers.StringLookup(vocabulary=unique_movie_ids, mask_token=\u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     34\u001b[39m     tf.keras.layers.Embedding(\u001b[38;5;28mlen\u001b[39m(unique_movie_ids) + \u001b[32m1\u001b[39m, embedding_dim)\n\u001b[32m     35\u001b[39m ])\n\u001b[32m     37\u001b[39m \u001b[38;5;28mself\u001b[39m.task = tfrs.tasks.Retrieval(\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     metrics=\u001b[43mtfrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFactorizedTopK\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcandidates\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py:79\u001b[39m, in \u001b[36mFactorizedTopK.__init__\u001b[39m\u001b[34m(self, candidates, ks, name)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(name=name)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(candidates, tf.data.Dataset):\n\u001b[32m     78\u001b[39m   candidates = (\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m       \u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorized_top_k\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m       .index_from_dataset(candidates)\n\u001b[32m     81\u001b[39m   )\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._ks = ks\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m._candidates = candidates\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/tensorflow_recommenders/layers/factorized_top_k.py:376\u001b[39m, in \u001b[36mStreaming.__init__\u001b[39m\u001b[34m(self, query_model, k, handle_incomplete_batches, num_parallel_calls, sorted_order)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28mself\u001b[39m._num_parallel_calls = num_parallel_calls\n\u001b[32m    374\u001b[39m \u001b[38;5;28mself\u001b[39m._sorted = sorted_order\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28mself\u001b[39m._counter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcounter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/layers/layer.py:575\u001b[39m, in \u001b[36mLayer.add_weight\u001b[39m\u001b[34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, overwrite_with_gradient, name)\u001b[39m\n\u001b[32m    573\u001b[39m initializer = initializers.get(initializer)\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m backend.name_scope(\u001b[38;5;28mself\u001b[39m.name, caller=\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     variable = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# Will be added to layer.losses\u001b[39;00m\n\u001b[32m    585\u001b[39m variable.regularizer = regularizers.get(regularizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:205\u001b[39m, in \u001b[36mVariable.__init__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(initializer):\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[38;5;28mself\u001b[39m._shape = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m         \u001b[38;5;28mself\u001b[39m._initialize_with_initializer(initializer)\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:227\u001b[39m, in \u001b[36mVariable._validate_shape\u001b[39m\u001b[34m(self, shape)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     shape = \u001b[43mstandardize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m shape:\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mShapes used to initialize variables must be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfully-defined (no `None` dimensions). Received: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    232\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for variable path=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    233\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:607\u001b[39m, in \u001b[36mstandardize_shape\u001b[39m\u001b[34m(shape)\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_int_dtype(\u001b[38;5;28mtype\u001b[39m(e)):\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to a shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound invalid entry \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m of type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m     )\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e < \u001b[32m0\u001b[39m:\n\u001b[32m    612\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    613\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to a shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    614\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNegative dimensions are not allowed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Cannot convert '('c', 'o', 'u', 'n', 't', 'e', 'r')' to a shape. Found invalid entry 'c' of type '<class 'str'>'. "
     ]
    }
   ],
   "source": [
    "# Prepare batched, cached datasets for efficiency\n",
    "cached_train = train_ds.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test_ds.batch(4096).cache()\n",
    "\n",
    "model = MovieLensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(cached_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1908cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_movie_ids type: <class 'numpy.ndarray'>\n",
      "unique_movie_ids shape: (1651,)\n",
      "First 10 movie ids: ['381' '602' '431' '875' '182' '1074' '286' '496' '15' '184']\n",
      "First element type: <class 'str'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '('c', 'o', 'u', 'n', 't', 'e', 'r')' to a shape. Found invalid entry 'c' of type '<class 'str'>'. ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task(user_embeddings, movie_embeddings)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Instantiate and train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m model = \u001b[43mMovieLensModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m model.compile(optimizer=tf.keras.optimizers.Adagrad(\u001b[32m0.1\u001b[39m))\n\u001b[32m     60\u001b[39m model.fit(cached_train, epochs=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mMovieLensModel.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.user_model = tf.keras.Sequential([\n\u001b[32m     39\u001b[39m     tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=\u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     40\u001b[39m     tf.keras.layers.Embedding(\u001b[38;5;28mlen\u001b[39m(unique_user_ids) + \u001b[32m1\u001b[39m, embedding_dim)\n\u001b[32m     41\u001b[39m ])\n\u001b[32m     42\u001b[39m \u001b[38;5;28mself\u001b[39m.movie_model = tf.keras.Sequential([\n\u001b[32m     43\u001b[39m     tf.keras.layers.StringLookup(vocabulary=unique_movie_ids, mask_token=\u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     44\u001b[39m     tf.keras.layers.Embedding(\u001b[38;5;28mlen\u001b[39m(unique_movie_ids) + \u001b[32m1\u001b[39m, embedding_dim)\n\u001b[32m     45\u001b[39m ])\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m.task = tfrs.tasks.Retrieval(\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     metrics=\u001b[43mtfrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFactorizedTopK\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcandidates\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/tensorflow_recommenders/metrics/factorized_top_k.py:79\u001b[39m, in \u001b[36mFactorizedTopK.__init__\u001b[39m\u001b[34m(self, candidates, ks, name)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(name=name)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(candidates, tf.data.Dataset):\n\u001b[32m     78\u001b[39m   candidates = (\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m       \u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorized_top_k\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStreaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m       .index_from_dataset(candidates)\n\u001b[32m     81\u001b[39m   )\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._ks = ks\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m._candidates = candidates\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/tensorflow_recommenders/layers/factorized_top_k.py:376\u001b[39m, in \u001b[36mStreaming.__init__\u001b[39m\u001b[34m(self, query_model, k, handle_incomplete_batches, num_parallel_calls, sorted_order)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28mself\u001b[39m._num_parallel_calls = num_parallel_calls\n\u001b[32m    374\u001b[39m \u001b[38;5;28mself\u001b[39m._sorted = sorted_order\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28mself\u001b[39m._counter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcounter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/layers/layer.py:575\u001b[39m, in \u001b[36mLayer.add_weight\u001b[39m\u001b[34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, overwrite_with_gradient, name)\u001b[39m\n\u001b[32m    573\u001b[39m initializer = initializers.get(initializer)\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m backend.name_scope(\u001b[38;5;28mself\u001b[39m.name, caller=\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     variable = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[38;5;66;03m# Will be added to layer.losses\u001b[39;00m\n\u001b[32m    585\u001b[39m variable.regularizer = regularizers.get(regularizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:205\u001b[39m, in \u001b[36mVariable.__init__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(initializer):\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[38;5;28mself\u001b[39m._shape = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m         \u001b[38;5;28mself\u001b[39m._initialize_with_initializer(initializer)\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:227\u001b[39m, in \u001b[36mVariable._validate_shape\u001b[39m\u001b[34m(self, shape)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     shape = \u001b[43mstandardize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m shape:\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mShapes used to initialize variables must be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfully-defined (no `None` dimensions). Received: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    232\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for variable path=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    233\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/development/tsuna-mayo/venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py:607\u001b[39m, in \u001b[36mstandardize_shape\u001b[39m\u001b[34m(shape)\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_int_dtype(\u001b[38;5;28mtype\u001b[39m(e)):\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to a shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound invalid entry \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m of type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m     )\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e < \u001b[32m0\u001b[39m:\n\u001b[32m    612\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    613\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to a shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    614\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNegative dimensions are not allowed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Cannot convert '('c', 'o', 'u', 'n', 't', 'e', 'r')' to a shape. Found invalid entry 'c' of type '<class 'str'>'. "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"../data/movielens/cleaned_ratings.csv\")\n",
    "train = df.sample(frac=0.8, random_state=42)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "# Get unique IDs as arrays of strings\n",
    "unique_user_ids = np.array(train[\"user_id\"].astype(str).unique())\n",
    "unique_movie_ids = np.array(train[\"movie_id\"].astype(str).unique())\n",
    "\n",
    "# Print debug info\n",
    "print(\"unique_movie_ids type:\", type(unique_movie_ids))\n",
    "print(\"unique_movie_ids shape:\", unique_movie_ids.shape)\n",
    "print(\"First 10 movie ids:\", unique_movie_ids[:10])\n",
    "print(\"First element type:\", type(unique_movie_ids[0]))\n",
    "\n",
    "# Make tf.data.Dataset candidates\n",
    "candidates = tf.data.Dataset.from_tensor_slices(unique_movie_ids).batch(128)\n",
    "\n",
    "# Build datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": train[\"user_id\"].astype(str).values,\n",
    "    \"movie_id\": train[\"movie_id\"].astype(str).values,\n",
    "    \"rating\": train[\"rating\"].astype(float).values,\n",
    "})\n",
    "cached_train = train_ds.shuffle(100_000).batch(8192).cache()\n",
    "\n",
    "# Model definition\n",
    "class MovieLensModel(tfrs.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dim = 32\n",
    "\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=unique_movie_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_ids) + 1, embedding_dim)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=candidates\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_id\"])\n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "# Instantiate and train\n",
    "model = MovieLensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
